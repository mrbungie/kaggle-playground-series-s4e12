{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.preprocess import treat_dataset_pandas_init, build_preprocessing_pipeline,INIT_NUMERICAL_COLS, numerical_features\n",
    "\n",
    "from utils.metrics import rmsle_metric\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import root_mean_squared_log_error\n",
    "from sklearn.ensemble import StackingRegressor, HistGradientBoostingRegressor\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from utils.categoricals import CategoricalToStringTransformer, CategoricalEncoder, CatogoricalUnknownTransformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"playground-series-s4e12/train.csv\")#.sample(frac=0.1)\n",
    "test_data = pd.read_csv(\"playground-series-s4e12/test.csv\")\n",
    "\n",
    "treated_dataset = treat_dataset_pandas_init(train_data, process_as_category=True)\n",
    "treated_test_dataset = treat_dataset_pandas_init(test_data, process_as_category=True)\n",
    "\n",
    "\n",
    "#non_loged_train, non_loged_test = joblib.load(\"cat_non_loged.pkl\")\n",
    "\n",
    "#treated_dataset['non_log_oof_prediction'] = non_loged_train\n",
    "\n",
    "X_train = treated_dataset.drop(columns=[\"Premium Amount\"])\n",
    "y_train = treated_dataset[\"Premium Amount\"]\n",
    "\n",
    "treated_test_dataset = treated_test_dataset[X_train.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Health Score</th>\n",
       "      <th>Location</th>\n",
       "      <th>Policy Type</th>\n",
       "      <th>...</th>\n",
       "      <th>Income to Dependents Ratio</th>\n",
       "      <th>Income_per_Dependent</th>\n",
       "      <th>CreditScore_InsuranceDuration</th>\n",
       "      <th>Health_Risk_Score</th>\n",
       "      <th>Credit_Health_Score</th>\n",
       "      <th>Health_Age_Interaction</th>\n",
       "      <th>Claims v Duration</th>\n",
       "      <th>Health vs Claims</th>\n",
       "      <th>Cat Credit Score</th>\n",
       "      <th>Int Credit Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>10049.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>22.598761</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Premium</td>\n",
       "      <td>...</td>\n",
       "      <td>5024.5</td>\n",
       "      <td>5024.5</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>3.870062</td>\n",
       "      <td>8406.738970</td>\n",
       "      <td>429.376453</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>7.532920</td>\n",
       "      <td>372.0</td>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>31678.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Master's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.569731</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Comprehensive</td>\n",
       "      <td>...</td>\n",
       "      <td>7919.5</td>\n",
       "      <td>7919.5</td>\n",
       "      <td>1388.0</td>\n",
       "      <td>4.221513</td>\n",
       "      <td>10805.393307</td>\n",
       "      <td>607.219509</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.784865</td>\n",
       "      <td>694.0</td>\n",
       "      <td>694.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>25602.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>3.0</td>\n",
       "      <td>High School</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>47.177549</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Premium</td>\n",
       "      <td>...</td>\n",
       "      <td>6400.5</td>\n",
       "      <td>6400.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.641123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1085.083634</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>23.588775</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>141855.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.938144</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Basic</td>\n",
       "      <td>...</td>\n",
       "      <td>47285.0</td>\n",
       "      <td>47285.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>4.453093</td>\n",
       "      <td>4014.298906</td>\n",
       "      <td>229.701027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.469072</td>\n",
       "      <td>367.0</td>\n",
       "      <td>367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>39651.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>20.376094</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Premium</td>\n",
       "      <td>...</td>\n",
       "      <td>19825.5</td>\n",
       "      <td>19825.5</td>\n",
       "      <td>2392.0</td>\n",
       "      <td>3.981195</td>\n",
       "      <td>12184.903989</td>\n",
       "      <td>427.897966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.376094</td>\n",
       "      <td>598.0</td>\n",
       "      <td>598.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199995</th>\n",
       "      <td>36.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>27316.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>13.772907</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Premium</td>\n",
       "      <td>...</td>\n",
       "      <td>27316.0</td>\n",
       "      <td>27316.0</td>\n",
       "      <td>1116.0</td>\n",
       "      <td>4.311355</td>\n",
       "      <td>5123.521323</td>\n",
       "      <td>495.824644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>372.0</td>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199996</th>\n",
       "      <td>54.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>35786.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>11.483482</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Comprehensive</td>\n",
       "      <td>...</td>\n",
       "      <td>35786.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>4.425826</td>\n",
       "      <td>6855.638903</td>\n",
       "      <td>620.108041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>597.0</td>\n",
       "      <td>597.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199997</th>\n",
       "      <td>19.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>51884.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Master's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.724469</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Basic</td>\n",
       "      <td>...</td>\n",
       "      <td>51884.0</td>\n",
       "      <td>51884.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.263777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>279.764902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.724469</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199998</th>\n",
       "      <td>55.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.547381</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Premium</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1628.0</td>\n",
       "      <td>4.072631</td>\n",
       "      <td>7548.784101</td>\n",
       "      <td>1020.105960</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>9.273691</td>\n",
       "      <td>407.0</td>\n",
       "      <td>407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199999</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.125323</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Premium</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3012.0</td>\n",
       "      <td>4.493734</td>\n",
       "      <td>5082.912134</td>\n",
       "      <td>212.631783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.125323</td>\n",
       "      <td>502.0</td>\n",
       "      <td>502.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200000 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age  Gender  Annual Income Marital Status  Number of Dependents  \\\n",
       "0        19.0  Female        10049.0        Married                   1.0   \n",
       "1        39.0  Female        31678.0       Divorced                   3.0   \n",
       "2        23.0    Male        25602.0       Divorced                   3.0   \n",
       "3        21.0    Male       141855.0        Married                   2.0   \n",
       "4        21.0    Male        39651.0         Single                   1.0   \n",
       "...       ...     ...            ...            ...                   ...   \n",
       "1199995  36.0  Female        27316.0        Married                   0.0   \n",
       "1199996  54.0    Male        35786.0       Divorced                   NaN   \n",
       "1199997  19.0    Male        51884.0       Divorced                   0.0   \n",
       "1199998  55.0    Male            NaN         Single                   1.0   \n",
       "1199999  21.0  Female            NaN       Divorced                   0.0   \n",
       "\n",
       "        Education Level     Occupation  Health Score  Location    Policy Type  \\\n",
       "0            Bachelor's  Self-Employed     22.598761     Urban        Premium   \n",
       "1              Master's            NaN     15.569731     Rural  Comprehensive   \n",
       "2           High School  Self-Employed     47.177549  Suburban        Premium   \n",
       "3            Bachelor's            NaN     10.938144     Rural          Basic   \n",
       "4            Bachelor's  Self-Employed     20.376094     Rural        Premium   \n",
       "...                 ...            ...           ...       ...            ...   \n",
       "1199995        Master's     Unemployed     13.772907     Urban        Premium   \n",
       "1199996        Master's  Self-Employed     11.483482     Rural  Comprehensive   \n",
       "1199997        Master's            NaN     14.724469  Suburban          Basic   \n",
       "1199998             PhD            NaN     18.547381  Suburban        Premium   \n",
       "1199999             PhD            NaN     10.125323     Rural        Premium   \n",
       "\n",
       "         ...  Income to Dependents Ratio  Income_per_Dependent  \\\n",
       "0        ...                      5024.5                5024.5   \n",
       "1        ...                      7919.5                7919.5   \n",
       "2        ...                      6400.5                6400.5   \n",
       "3        ...                     47285.0               47285.0   \n",
       "4        ...                     19825.5               19825.5   \n",
       "...      ...                         ...                   ...   \n",
       "1199995  ...                     27316.0               27316.0   \n",
       "1199996  ...                     35786.0                   NaN   \n",
       "1199997  ...                     51884.0               51884.0   \n",
       "1199998  ...                         NaN                   NaN   \n",
       "1199999  ...                         NaN                   NaN   \n",
       "\n",
       "         CreditScore_InsuranceDuration  Health_Risk_Score Credit_Health_Score  \\\n",
       "0                               1860.0           3.870062         8406.738970   \n",
       "1                               1388.0           4.221513        10805.393307   \n",
       "2                                  NaN           2.641123                 NaN   \n",
       "3                                367.0           4.453093         4014.298906   \n",
       "4                               2392.0           3.981195        12184.903989   \n",
       "...                                ...                ...                 ...   \n",
       "1199995                         1116.0           4.311355         5123.521323   \n",
       "1199996                         2388.0           4.425826         6855.638903   \n",
       "1199997                            NaN           4.263777                 NaN   \n",
       "1199998                         1628.0           4.072631         7548.784101   \n",
       "1199999                         3012.0           4.493734         5082.912134   \n",
       "\n",
       "        Health_Age_Interaction Claims v Duration Health vs Claims  \\\n",
       "0                   429.376453          0.400000         7.532920   \n",
       "1                   607.219509          0.500000         7.784865   \n",
       "2                  1085.083634          0.333333        23.588775   \n",
       "3                   229.701027          1.000000         5.469072   \n",
       "4                   427.897966          0.000000        20.376094   \n",
       "...                        ...               ...              ...   \n",
       "1199995             495.824644               NaN              NaN   \n",
       "1199996             620.108041               NaN              NaN   \n",
       "1199997             279.764902          0.000000        14.724469   \n",
       "1199998            1020.105960          0.250000         9.273691   \n",
       "1199999             212.631783          0.000000        10.125323   \n",
       "\n",
       "         Cat Credit Score  Int Credit Score  \n",
       "0                   372.0             372.0  \n",
       "1                   694.0             694.0  \n",
       "2                    <NA>               NaN  \n",
       "3                   367.0             367.0  \n",
       "4                   598.0             598.0  \n",
       "...                   ...               ...  \n",
       "1199995             372.0             372.0  \n",
       "1199996             597.0             597.0  \n",
       "1199997              <NA>               NaN  \n",
       "1199998             407.0             407.0  \n",
       "1199999             502.0             502.0  \n",
       "\n",
       "[1200000 rows x 70 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Development\\insurance\\venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [01:02:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.1313341554478178, Test: 1.1409681885080667\n",
      "Starting\n",
      "Train: 1.1334130017937218, Test: 1.1405699811180052\n",
      "Starting\n",
      "Train: 1.1318561732730583, Test: 1.1368908317630717\n",
      "Starting\n",
      "Train: 1.1339068287411136, Test: 1.1412503017142028\n",
      "Starting\n",
      "Train: 1.1314456612709363, Test: 1.14011610949857\n"
     ]
    }
   ],
   "source": [
    "# Define a 60-40 split\n",
    "splitter = ShuffleSplit(n_splits=5, test_size=0.2, random_state=1)\n",
    "splitter = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "models = []\n",
    "for train_idx, val_idx in splitter.split(X_train):\n",
    "    print(\"Starting\")\n",
    "    # Prepare data for LightGBM\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    {'learning_rate': 0.4290296903723802, 'n_estimators': 865, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.8352284080073455, 'colsample_bytree': 0.7100615955636335, 'gamma': 2.8086205574716985, 'lambda': 2.9562811725383225, 'alpha': 9.51949783566794}\n",
    "    \n",
    "    full_pipeline = Pipeline([\n",
    "        (\"model\",xgb.XGBRegressor(\n",
    "            learning_rate=0.4290296903723802,\n",
    "            n_estimators=187,\n",
    "            max_depth=4,\n",
    "            min_child_weight=1,\n",
    "            subsample=0.8352284080073455,\n",
    "            colsample_bytree=0.7100615955636335,\n",
    "            gamma=2.8086205574716985,\n",
    "            reg_lambda=2.9562811725383225,\n",
    "            reg_alpha=9.51949783566794,\n",
    "            enable_categorical=True,\n",
    "            tree_method=\"hist\",\n",
    "            objective=\"reg:squarederror\",\n",
    "            device=\"cuda\"\n",
    "        ))\n",
    "    ])\n",
    "    full_pipeline.fit(X_train_fold, y_train_fold)\n",
    "    models.append(full_pipeline)\n",
    "    \n",
    "    train_predictions = np.clip(full_pipeline.predict(X_train_fold), 20, 5000)\n",
    "    val_predictions = np.clip(full_pipeline.predict(X_val_fold), 20, 5000)\n",
    "    results.append({\n",
    "        \"oof_predictions\": {\n",
    "            \"index\": val_idx,\n",
    "            \"predictions\": val_predictions,\n",
    "        },\n",
    "        \"test_predictions\": {\n",
    "            \"predictions\": np.clip(full_pipeline.predict(treated_test_dataset), 20, 5000),\n",
    "        }\n",
    "    })\n",
    "\n",
    "    train_score = root_mean_squared_log_error(train_predictions, y_train_fold)\n",
    "    val_score = root_mean_squared_log_error(val_predictions, y_val_fold)\n",
    "\n",
    "    print(f\"Train: {train_score}, Test: {val_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      8,      21,      27, ..., 1199965, 1199992, 1199995])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Fitting catboost - Start 2024-12-30 01:08:08.145678\n",
      "Fitting catboost - End 2024-12-30 01:08:18.428396\n",
      "Fitting xgboost - Start 2024-12-30 01:08:18.428396\n",
      "Fitting xgboost - End 2024-12-30 01:08:21.549552\n",
      "Fitting stack_model - Start 2024-12-30 01:08:21.550553\n",
      "Fitting stack_model - End 2024-12-30 01:08:22.608182\n",
      "Train: 1.1203557160804973, Test: 1.1303386271811962\n",
      "Starting\n",
      "Fitting catboost - Start 2024-12-30 01:08:24.622183\n",
      "Fitting catboost - End 2024-12-30 01:08:35.180649\n",
      "Fitting xgboost - Start 2024-12-30 01:08:35.180649\n",
      "Fitting xgboost - End 2024-12-30 01:08:38.181464\n",
      "Fitting stack_model - Start 2024-12-30 01:08:38.181464\n",
      "Fitting stack_model - End 2024-12-30 01:08:39.225506\n",
      "Train: 1.1201931406560004, Test: 1.128188044562507\n",
      "Starting\n",
      "Fitting catboost - Start 2024-12-30 01:08:41.321513\n",
      "Fitting catboost - End 2024-12-30 01:08:51.487303\n",
      "Fitting xgboost - Start 2024-12-30 01:08:51.487303\n",
      "Fitting xgboost - End 2024-12-30 01:08:54.582378\n",
      "Fitting stack_model - Start 2024-12-30 01:08:54.583379\n",
      "Fitting stack_model - End 2024-12-30 01:08:55.648775\n",
      "Train: 1.1208003822656853, Test: 1.126497653212883\n",
      "Starting\n",
      "Fitting catboost - Start 2024-12-30 01:08:57.698775\n",
      "Fitting catboost - End 2024-12-30 01:09:08.402845\n",
      "Fitting xgboost - Start 2024-12-30 01:09:08.402845\n",
      "Fitting xgboost - End 2024-12-30 01:09:11.563845\n",
      "Fitting stack_model - Start 2024-12-30 01:09:11.564846\n",
      "Fitting stack_model - End 2024-12-30 01:09:12.685846\n",
      "Train: 1.1210283823324414, Test: 1.127792050794714\n",
      "Starting\n",
      "Fitting catboost - Start 2024-12-30 01:09:14.797846\n",
      "Fitting catboost - End 2024-12-30 01:09:25.403025\n",
      "Fitting xgboost - Start 2024-12-30 01:09:25.403025\n",
      "Fitting xgboost - End 2024-12-30 01:09:28.533780\n",
      "Fitting stack_model - Start 2024-12-30 01:09:28.533780\n",
      "Fitting stack_model - End 2024-12-30 01:09:29.658382\n",
      "Train: 1.1205214324247446, Test: 1.1295959922260437\n"
     ]
    }
   ],
   "source": [
    "stack_results = []\n",
    "stack_models = []\n",
    "for train_idx, val_idx in splitter.split(X_train):\n",
    "    print(\"Starting\")\n",
    "    # Prepare data for LightGBM\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "    categorical_features = [col for col in X_train_fold.columns if X_train_fold[col].dtype == \"category\"]\n",
    "    \n",
    "    X_train_fold = X_train_fold.replace([pd.NA], np.nan)\n",
    "    X_val_fold = X_val_fold.replace([pd.NA], np.nan)\n",
    "    \n",
    "    catboost_model = Pipeline([\n",
    "        (\"categorical_to_string\", CatogoricalUnknownTransformer()),\n",
    "        (\"model\",CatBoostRegressor(iterations=100,\n",
    "                          early_stopping_rounds=10,\n",
    "                          grow_policy = 'Depthwise',\n",
    "                          depth=4,\n",
    "                          cat_features=categorical_features,\n",
    "                          random_state=42,\n",
    "                          l2_leaf_reg = 1,\n",
    "                          learning_rate=0.4,verbose=0))\n",
    "    ])\n",
    "    print(\"Fitting catboost - Start\", datetime.now())\n",
    "    catboost_model.fit(X_train_fold, y_train_fold)\n",
    "    print(\"Fitting catboost - End\", datetime.now())\n",
    "\n",
    "    \n",
    "    #linear_model_pipeline = Pipeline([\n",
    "    #    (\"preprocessing\", build_preprocessing_pipeline(train_data=X_train_fold, imputation_method=\"simple\", binning_method=\"opti-means\", categorical_to_string=True)),\n",
    "    #    (\"model\", LinearRegression())\n",
    "    #])\n",
    "    #print(\"Fitting linear model - Start\", datetime.now())\n",
    "    #linear_model_pipeline.fit(X_train_fold, y_train_fold)\n",
    "    #print(\"Fitting linear model - End\", datetime.now())\n",
    "    \n",
    "    \"\"\"\n",
    "    hist_pipeline = Pipeline([\n",
    "        (\"preprocessing\", build_preprocessing_pipeline(train_data=X_train_fold, imputation_method=\"simple\", categorical_to_string=True)),\n",
    "        (\"model\", HistGradientBoostingRegressor())\n",
    "    ])\n",
    "    \"\"\"\n",
    "    \n",
    "    xgboost = xgb.XGBRegressor(\n",
    "            learning_rate=0.4290296903723802,\n",
    "            n_estimators=187,\n",
    "            max_depth=4,\n",
    "            min_child_weight=1,\n",
    "            subsample=0.8352284080073455,\n",
    "            colsample_bytree=0.7100615955636335,\n",
    "            gamma=2.8086205574716985,\n",
    "            reg_lambda=2.9562811725383225,\n",
    "            reg_alpha=9.51949783566794,\n",
    "            enable_categorical=True,\n",
    "            tree_method=\"hist\",\n",
    "            objective=\"reg:squarederror\",\n",
    "            device=\"cuda\"\n",
    "        )\n",
    "    print(\"Fitting xgboost - Start\", datetime.now())\n",
    "    xgboost.fit(X_train_fold, y_train_fold)\n",
    "    print(\"Fitting xgboost - End\", datetime.now())\n",
    "\n",
    "    stack_model = StackingRegressor(\n",
    "        estimators=[\n",
    "            #(\"linear_model\", linear_model_pipeline),\n",
    "            (\"xgboost\", xgboost),\n",
    "            (\"catboost\", catboost_model)\n",
    "        ],\n",
    "        cv='prefit',\n",
    "        #final_estimator=BayesianRidge(),\n",
    "        final_estimator=xgb.XGBRegressor(enable_categorical=True, eta=0.1, colsample_bytree=0.9, n_estimators=100, max_depth=4, device=\"cuda\", tree_method=\"hist\"),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    stack_models.append(stack_model)\n",
    "\n",
    "    print(\"Fitting stack_model - Start\", datetime.now())    \n",
    "    stack_model.fit(X_train_fold, y_train_fold)\n",
    "    print(\"Fitting stack_model - End\", datetime.now())\n",
    "\n",
    "    train_predictions = np.clip(stack_model.predict(X_train_fold), 20, 5000)\n",
    "    val_predictions = np.clip(stack_model.predict(X_val_fold), 20, 5000)\n",
    "    stack_results.append({\n",
    "        \"oof_predictions\": {\n",
    "            \"index\": val_idx,\n",
    "            \"predictions\": val_predictions,\n",
    "        },\n",
    "        \"test_predictions\": {\n",
    "            \"predictions\": np.clip(stack_model.predict(treated_test_dataset), 20, 5000),\n",
    "        }\n",
    "    })\n",
    "\n",
    "    train_score = root_mean_squared_log_error(train_predictions, y_train_fold)\n",
    "    val_score = root_mean_squared_log_error(val_predictions, y_val_fold)\n",
    "\n",
    "    print(f\"Train: {train_score}, Test: {val_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(treated_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat_non_loged_local.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof = pd.concat([pd.DataFrame(stack_result['oof_predictions']) for stack_result in stack_results]).set_index('index').sort_index()\n",
    "test_predictions = np.array([result['test_predictions']['predictions'] for result in stack_results]).mean(axis=0)\n",
    "\n",
    "joblib.dump([oof,test_predictions],\"cat_non_loged_local.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
